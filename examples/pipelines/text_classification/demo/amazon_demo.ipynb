{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon sentiment demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read data sample\n",
    "\n",
    "You can skip this step if you do not want to test on real amazon data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = bz2.BZ2File('../data/train.s.ft.txt.bz2')\n",
    "test_file = bz2.BZ2File('../data/test.s.ft.txt.bz2')\n",
    "train_file_lines = train_file.readlines()\n",
    "test_file_lines = test_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_lines = [x.decode('utf-8') for x in train_file_lines]\n",
    "test_file_lines = [x.decode('utf-8') for x in test_file_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in train_file_lines]\n",
    "train_sentences = [x.split(' ', 1)[1][:-1].lower() for x in train_file_lines]\n",
    "for i in range(len(train_sentences)):\n",
    "    train_sentences[i] = re.sub('\\d','0',train_sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test_file_lines]\n",
    "test_sentences = [x.split(' ', 1)[1][:-1].lower() for x in test_file_lines]\n",
    "for i in range(len(test_sentences)):\n",
    "    test_sentences[i] = re.sub('\\d','0', test_sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_sentences)):\n",
    "    if 'www.' in train_sentences[i] or 'http:' in train_sentences[i] or 'https:' in train_sentences[i] or '.com' in train_sentences[i]:\n",
    "        train_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", train_sentences[i])\n",
    "        \n",
    "for i in range(len(test_sentences)):\n",
    "    if 'www.' in test_sentences[i] or 'http:' in test_sentences[i] or 'https:' in test_sentences[i] or '.com' in test_sentences[i]:\n",
    "        test_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", test_sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import TextWrapper\n",
    "wrapper = TextWrapper(subsequent_indent='\\t  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: great cd: my lovely pat has one of the great voices of her generation.\n",
      "\t  i have listened to this cd for years and i still love it. when i'm\n",
      "\t  in a good mood it makes me feel better. a bad mood just evaporates\n",
      "\t  like sugar in the rain. this cd just oozes life. vocals are jusat\n",
      "\t  stuunning and lyrics just kill. one of life's hidden gems. this is\n",
      "\t  a desert isle cd in my book. why she never made it big is just\n",
      "\t  beyond me. everytime i play this, no matter black, white, young,\n",
      "\t  old, male, female everybody says one thing \"who was that singing ?\"\n",
      "Label:    1\n"
     ]
    }
   ],
   "source": [
    "review = test_sentences[0]\n",
    "review_label = test_labels[0]\n",
    "print(\"Sentence:\", \"\\n\".join(wrapper.wrap(review)))\n",
    "print(\"Label:   \", review_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perform an inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydrosdk import Cluster, Application\n",
    "import grpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = Cluster(\n",
    "    http_address=\"<hydrosphere-http-address>\",\n",
    "    grpc_address=\"<hydrosphere-grpc-address>\",\n",
    "    ssl=True,                                         # turn off, if your Hydrosphere instance doesn't have\n",
    "    grpc_credentials=grpc.ssl_channel_credentials()   # TLS certificates installed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "\n",
    "For the tokenization we use the tokenizer model for which we've created an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "app1 = Application.find(cluster, \"<application-name>\")\n",
    "app1.lock_while_starting()\n",
    "predictor1 = app1.predictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = predictor1.predict({\"sentence\": review})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokenized': array([   95,    21,  1531,  4475,    44,    24,     7,     1,    30,\n",
       "         1917,     7,    79,  1957,     3,    20,  1030,     5,     8,\n",
       "           95,    11,   138,     2,     3,   127,    81,     6,    51,\n",
       "          110,    10,     4,    32,  2062,     6,   209,    43,   229,\n",
       "           91,     4,   128,  2062,    36,    33,  2304,    10,     1,\n",
       "         2274,     8,    95,    36,   154,  1031,    23,     2,   646,\n",
       "           36,  1528,    24,     7,  6335,  2461,  4235,     8,     9,\n",
       "            4,  3888, 12033,    95,    10,    21,    19,   182,    97,\n",
       "          122,   129,     6,   220,     9,    36,   861,    43,  2693,\n",
       "            3,   235,     8,    54,   615,   429,   576,   459,   134,\n",
       "         1776,  1351,  2198,   498,    24,   162,    72,    13,    12,\n",
       "          910])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator\n",
    "\n",
    "For the sentiment prediction we use the estimator model for which we've created an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "app2 = Application.find(cluster, \"<application-name>\")\n",
    "app2.lock_while_starting()\n",
    "predictor2 = app2.predictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = predictor2.predict({\"tokenized\": result1[\"tokenized\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'confidence': 0.9660149216651917, 'label': 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction confidence: 0.9660149216651917\n",
      "Prediction label: 1\n",
      "Actual label: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction confidence:\", result2[\"confidence\"])\n",
    "print(\"Prediction label:\", result2[\"label\"])\n",
    "print(\"Actual label:\", review_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "\n",
    "For this test we've created a pipeline application that consists of two stages:\n",
    "\n",
    "- tokenization\n",
    "- sentiment estimation\n",
    "\n",
    "In this app we pass the whole review text and receive it's sentiment prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "app3 = Application.find(cluster, \"<application-name>\")\n",
    "app3.lock_while_starting()\n",
    "predictor3 = app3.predictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = predictor3.predict({\"sentence\": review})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction confidence: 0.9660149216651917\n",
      "Prediction label: 1\n",
      "Actual label: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction confidence:\", result3[\"confidence\"])\n",
    "print(\"Prediction label:\", result3[\"label\"])\n",
    "print(\"Actual label:\", review_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
