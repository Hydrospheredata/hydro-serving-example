{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hydro-serving / Tensorflow\n",
    "\n",
    "## Proposal\n",
    "User trains model in genuine TF environment. We don't know where or how it's done. \n",
    "All we care about is a MetaGraphDef with serving Signatures.\n",
    "Current notebook exploits Tensorflow Serving techniquies and upgrades them.\n",
    "\n",
    "### Tensorflow Serving \n",
    "1. User trains model\n",
    "2. User defines one or more signatures for graph.\n",
    "3. User uses builder to export model.\n",
    "\n",
    "Signatures in Tensorflow are limited: classification, prediction and regression signatures with input/output conditions.\n",
    "\n",
    "### Hydro-serving\n",
    "1. User trains model\n",
    "2. User defines exactly one signature for graph.\n",
    "3. User uses builder to export model.\n",
    "\n",
    "As signature name user must use `tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY`.\n",
    "There are no restrictions for input/output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 157.567650833\n",
      "Epoch: 0002 cost= 40.614061964\n",
      "Epoch: 0003 cost= 25.145855488\n",
      "Epoch: 0004 cost= 17.507262625\n",
      "Epoch: 0005 cost= 12.603052658\n",
      "Epoch: 0006 cost= 9.349792043\n",
      "Epoch: 0007 cost= 6.964975329\n",
      "Epoch: 0008 cost= 5.141477290\n",
      "Epoch: 0009 cost= 3.829109068\n",
      "Epoch: 0010 cost= 2.906461860\n",
      "Epoch: 0011 cost= 2.165220779\n",
      "Epoch: 0012 cost= 1.642120135\n",
      "Epoch: 0013 cost= 1.244818602\n",
      "Epoch: 0014 cost= 1.031664681\n",
      "Epoch: 0015 cost= 0.840682691\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9455\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngaAIPxAU4QeCIvxAUP8PyDp1Nv3p+3cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116c8d0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "Exporting trained model to /tmp/tf_model...\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'/tmp/tf_model/saved_model.pb'\n",
      "Export finished\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "A Multilayer Perceptron implementation example using TensorFlow library.\n",
    "This example is using the MNIST database of handwritten digits\n",
    "(http://yann.lecun.com/exdb/mnist/)\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input], name=\"x\")\n",
    "y = tf.placeholder(\"float\", [None, n_classes], name=\"y\")\n",
    "\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.add(tf.matmul(layer_2, weights['out']), biases['out'], name = \"out_classes\")\n",
    "    return out_layer\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "rand = tf.random_normal([2, 3], mean=-1, stddev=4)\n",
    "output = tf.argmax(pred,1)\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            feed = {x: batch_x, y: batch_y}\n",
    "            _, c = sess.run([optimizer, cost], feed_dict=feed)\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                \"{:.9f}\".format(avg_cost))\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n",
    "    batch_x = mnist.train.next_batch(1)[0][0].reshape(1, 784)\n",
    "    \n",
    "    plt.imshow(batch_x.reshape(28, 28))\n",
    "    plt.show()\n",
    "    \n",
    "    bla = {\n",
    "         'x:0': batch_x\n",
    "    }\n",
    "    print(sess.run(output, feed_dict=bla))\n",
    "    \n",
    "    export_path = \"/tmp/tf_model\"  \n",
    "    print('Exporting trained model to {0}...'.format(export_path))\n",
    "\n",
    "    shutil.rmtree(export_path)\n",
    "\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "\n",
    "    tensor_info_x = tf.saved_model.utils.build_tensor_info(x)\n",
    "    tensor_info_output = tf.saved_model.utils.build_tensor_info(output)\n",
    "    tensor_info_test = tf.saved_model.utils.build_tensor_info(rand)\n",
    "\n",
    "\n",
    "    \n",
    "    classification_signature = (\n",
    "      tf.saved_model.signature_def_utils.build_signature_def(\n",
    "          inputs={\n",
    "              'images': tensor_info_x\n",
    "          },\n",
    "          outputs={\n",
    "              'labels': tensor_info_output,\n",
    "              'labels2': tensor_info_output,\n",
    "              'random': tensor_info_test\n",
    "          },\n",
    "          method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME)\n",
    "    )\n",
    "    \n",
    "    legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n",
    "    builder.add_meta_graph_and_variables(\n",
    "      sess, [tf.saved_model.tag_constants.SERVING],\n",
    "      signature_def_map={\n",
    "          tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: classification_signature\n",
    "      },\n",
    "      legacy_init_op=legacy_init_op)\n",
    "    builder.save()\n",
    "    print('Export finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from b'/tmp/tf_model/variables/variables'\n",
      "['images']\n",
      "['labels', 'labels2', 'random']\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "{'x:0': matrix([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4QeS+n9W5CgdtXYSvAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119c56d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'labels': 8, 'labels2': 8, 'random': [6.999138832092285, -1.5135674476623535, 2.967315196990967], 'images': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.50196081,  0.50196081,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.50196081,  0.25098041,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.74901962,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.74901962,  0.50196081,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.50196081,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.74901962,  1.        ,  1.        ,  1.        ,\n",
      "        0.74901962,  0.25098041,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.25098041,  0.50196081,\n",
      "        0.25098041,  0.25098041,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.50196081,  1.        ,\n",
      "        1.        ,  1.        ,  0.50196081,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.50196081,  1.        ,  1.        ,  1.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.50196081,  1.        ,  1.        ,  0.50196081,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.50196081,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.50196081,\n",
      "        1.        ,  1.        ,  1.        ,  0.50196081,  0.        ,\n",
      "        0.        ,  0.        ,  0.25098041,  0.74901962,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.74901962,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.74901962,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.50196081,  0.50196081,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.74901962,  0.50196081,  0.25098041,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.74901962,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  0.25098041,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.25098041,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.50196081,  0.25098041,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.25098041,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.50196081,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
      "        1.        ,  0.74901962,  0.        ,  0.25098041,  0.50196081,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  0.25098041,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.50196081,  1.        ,  1.        ,  1.        ,  0.25098041,\n",
      "        0.        ,  0.        ,  0.        ,  0.25098041,  0.74901962,\n",
      "        1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.50196081,  1.        ,\n",
      "        1.        ,  0.50196081,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.25098041,  1.        ,  1.        ,\n",
      "        1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  1.        ,  1.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.25098041,\n",
      "        1.        ,  1.        ,  1.        ,  0.74901962,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  1.        ,\n",
      "        1.        ,  0.50196081,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.25098041,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  0.25098041,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.74901962,  1.        ,  1.        ,\n",
      "        0.25098041,  0.        ,  0.        ,  0.74901962,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  0.25098041,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.50196081,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  0.74901962,\n",
      "        0.25098041,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.74901962,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        1.        ,  0.25098041,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.50196081,  1.        ,\n",
      "        1.        ,  1.        ,  0.50196081,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32), 'answer': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]), 'kek': 1}, {'labels': 1, 'labels2': 1, 'random': [-0.24706846475601196, 0.8714470863342285, 7.541565895080566], 'images': array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.05882353,\n",
      "        0.13333334,  0.73725492,  1.        ,  0.92156869,  0.10196079,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.43529415,  0.98823535,  0.98823535,\n",
      "        0.98823535,  0.98823535,  0.77254909,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.43529415,  0.98823535,  0.98823535,  0.98823535,  0.95686281,\n",
      "        0.47058827,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.43529415,  0.98823535,\n",
      "        0.98823535,  0.98823535,  0.90196085,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.20392159,  0.80000007,  0.98823535,  0.98823535,  0.98823535,\n",
      "        0.96078438,  0.50588238,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.30588236,  0.98823535,\n",
      "        0.98823535,  0.98823535,  0.98823535,  0.92156869,  0.16470589,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.00392157,\n",
      "        0.19607845,  0.9333334 ,  0.98823535,  0.98823535,  0.98823535,\n",
      "        0.98823535,  0.90196085,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.04705883,  0.98823535,  0.98823535,\n",
      "        0.98823535,  0.98823535,  0.98823535,  0.98823535,  0.74901962,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.04705883,  0.98823535,  0.98823535,  0.98823535,  0.98823535,\n",
      "        0.98823535,  0.98823535,  0.03529412,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.04705883,  0.98823535,\n",
      "        0.98823535,  0.98823535,  0.98823535,  0.98823535,  0.627451  ,\n",
      "        0.01960784,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.04705883,  0.98823535,  0.98823535,  0.98823535,\n",
      "        0.98823535,  0.98823535,  0.16862746,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.65098041,\n",
      "        0.98823535,  0.98823535,  0.98823535,  0.98823535,  0.98823535,\n",
      "        0.16862746,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.90980399,  0.98823535,  0.98823535,\n",
      "        0.98823535,  0.98823535,  0.98823535,  0.16862746,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.90980399,  0.98823535,  0.98823535,  0.98823535,  0.94117653,\n",
      "        0.29803923,  0.00784314,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.17254902,  0.92941183,  0.98823535,\n",
      "        0.98823535,  0.98823535,  0.42745101,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.78039223,  0.98823535,  0.98823535,  0.98823535,  0.98823535,\n",
      "        0.62352943,  0.10588236,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.40784317,  0.95294124,\n",
      "        0.98823535,  0.98823535,  0.98823535,  0.98823535,  0.627451  ,\n",
      "        0.08235294,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.90980399,  0.98823535,  0.98823535,\n",
      "        0.98823535,  0.98823535,  0.56078434,  0.06666667,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.26666668,  0.98823535,  0.98823535,  0.98823535,  0.56862748,\n",
      "        0.07843138,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.00784314,  0.27450982,\n",
      "        0.98823535,  0.60784316,  0.05490196,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32), 'answer': array([ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]), 'kek': 2}]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "in_x, in_y = mnist.train.next_batch(1)\n",
    "in2_x, in2_y = mnist.train.next_batch(1)\n",
    "input_data = [\n",
    "    {\n",
    "        'images': in_x[0],\n",
    "        'answer': in_y[0],\n",
    "        \"kek\":1\n",
    "    },\n",
    "    {\n",
    "        'images': in2_x[0],\n",
    "        'answer': in2_y[0],\n",
    "        \"kek\":2\n",
    "    }\n",
    "]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    meta_graph = tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], export_path)\n",
    "    signature = meta_graph.signature_def['serving_default']\n",
    "    inputs = list(signature.inputs._values.keys())\n",
    "    outputs = list(signature.outputs._values.keys())\n",
    "    print(inputs)\n",
    "    print(outputs)\n",
    "    \n",
    "    input_tensors = {x: sess.graph.get_tensor_by_name(signature.inputs[x].name) for x in inputs}\n",
    "    output_tensors = {x: sess.graph.get_tensor_by_name(signature.outputs[x].name) for x in outputs}\n",
    "\n",
    "    \n",
    "    dicts = dict(zip(input_data[0], zip(*[d.values() for d in input_data])))\n",
    "    \n",
    "    feed_dict = {v.name: concatListOfArrs(list(dicts[k])) for (k, v) in input_tensors.items() }\n",
    "    \n",
    "    print(feed_dict)\n",
    "    \n",
    "#     plt.imshow(bla['x:0'].reshape(28, 28))\n",
    "#     plt.show()\n",
    "    \n",
    "    result = sess.run(output_tensors, feed_dict)\n",
    "    \n",
    "    result = {k: v.tolist() if type(v) is np.ndarray else v for k, v in result.items() }\n",
    "    \n",
    "    res = dict(list(result.items()) + list(dicts.items()))\n",
    "    res_list = [dict(zip(res,t)) for t in zip(*res.values())]\n",
    "    \n",
    "    print(res_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_x, in_y = mnist.train.next_batch(1)\n",
    "in2_x, in2_y = mnist.train.next_batch(1)\n",
    "input_data = [\n",
    "    {\n",
    "        'images': in_x[0],\n",
    "        'answer': in_y[0],\n",
    "        \"kek\":1\n",
    "    },\n",
    "    {\n",
    "        'images': in2_x[0],\n",
    "        'answer': in2_y[0],\n",
    "        \"kek\":2\n",
    "    }\n",
    "]\n",
    "dicts = dict(zip(input_data[0], zip(*[d.values() for d in input_data])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "feed = {x: batch_x, y: batch_y}\n",
    "print(type(feed[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concatListOfArrs(lst):\n",
    "    print(type(lst))\n",
    "    print(type(lst[0]))    \n",
    "    return np.matrix(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': [1, 2, 3, 4, 5], 'b': [3, 4, 1, 4, 5]}\n"
     ]
    }
   ],
   "source": [
    "a = {'a': [1,2,3,4,5]}\n",
    "b = {'b': [3,4,1,4,5]}\n",
    "\n",
    "c = dict(list(a.items()) + list(b.items()))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.47058827, 0.99215692, 0.99215692, 0.39607847, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.074509807, 0.88235301, 0.98823535, 0.89019614, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25882354, 0.98823535, 0.98823535, 0.4039216, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5529412, 0.98823535, 0.98823535, 0.10980393, 0.0, 0.0, 0.0, 0.0, 0.44705886, 0.34509805, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.60392159, 0.99215692, 0.99215692, 0.10980393, 0.0, 0.0, 0.0, 0.44705886, 1.0, 0.77254909, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.99215692, 0.98823535, 0.76862752, 0.035294119, 0.0, 0.0, 0.0, 0.73725492, 0.99215692, 0.76862752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14901961, 0.99215692, 0.98823535, 0.3137255, 0.0, 0.0, 0.0, 0.0, 0.88235301, 0.99215692, 0.42745101, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.63921571, 0.99215692, 0.79215693, 0.023529414, 0.0, 0.0, 0.0, 0.29803923, 0.97647065, 0.99215692, 0.32941177, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.88627458, 0.99607849, 0.77254909, 0.0, 0.0, 0.0, 0.027450982, 0.60392159, 0.99215692, 0.93725497, 0.14901961, 0.0, 0.0, 0.36078432, 0.57254905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.074509807, 0.90588242, 0.99215692, 0.47450984, 0.0, 0.0, 0.0, 0.32156864, 0.98823535, 0.98823535, 0.58823532, 0.0, 0.074509807, 0.6156863, 0.84705889, 0.76862752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.48235297, 0.98823535, 0.99215692, 0.84313732, 0.77254909, 0.77254909, 0.77647066, 0.91764712, 0.98823535, 0.98823535, 0.87450987, 0.77254909, 0.84313732, 0.98823535, 0.99215692, 0.76862752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20000002, 0.96470594, 0.98823535, 0.99215692, 0.98823535, 0.98823535, 0.98823535, 0.99215692, 0.98823535, 0.98823535, 0.98823535, 0.99215692, 0.98823535, 0.98823535, 0.98823535, 0.50196081, 0.086274512, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22352943, 0.99215692, 0.9450981, 0.63921571, 0.44313729, 0.44313729, 0.83529419, 0.99607849, 0.99215692, 0.99215692, 0.89411771, 0.44705886, 0.44313729, 0.098039225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.074509807, 0.32941177, 0.18431373, 0.0, 0.0, 0.0, 0.20000002, 0.99215692, 0.98823535, 0.76862752, 0.035294119, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.88235301, 0.99215692, 0.91372555, 0.24313727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29803923, 0.97647065, 0.99215692, 0.76862752, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027450982, 0.80000007, 0.99215692, 0.88627458, 0.14901961, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22352943, 0.98823535, 0.98823535, 0.44313729, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56470591, 0.98823535, 0.98823535, 0.098039225, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4666667, 0.98823535, 0.40000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "a, b = mnist.train.next_batch(1)\n",
    "print(list(a[0]))\n",
    "print(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
