{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hydro-serving / Tensorflow\n",
    "\n",
    "## Proposal\n",
    "User trains model in genuine TF environment. We don't know where or how it's done. \n",
    "All we care about is a MetaGraphDef with serving Signatures.\n",
    "Current notebook exploits Tensorflow Serving techniquies and upgrades them.\n",
    "\n",
    "### Tensorflow Serving \n",
    "1. User trains model\n",
    "2. User defines one or more signatures for graph.\n",
    "3. User uses builder to export model.\n",
    "\n",
    "Signatures in Tensorflow are limited: classification, prediction and regression signatures with input/output conditions.\n",
    "\n",
    "### Hydro-serving\n",
    "1. User trains model\n",
    "2. User defines exactly one signature for graph.\n",
    "3. User uses builder to export model.\n",
    "\n",
    "As signature name user must use `tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY`.\n",
    "There are no restrictions for input/output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 133.264602014\n",
      "Epoch: 0002 cost= 36.322912484\n",
      "Epoch: 0003 cost= 22.835460966\n",
      "Epoch: 0004 cost= 15.678414066\n",
      "Epoch: 0005 cost= 11.490850050\n",
      "Epoch: 0006 cost= 8.448159799\n",
      "Epoch: 0007 cost= 6.297038753\n",
      "Epoch: 0008 cost= 4.805425302\n",
      "Epoch: 0009 cost= 3.407793046\n",
      "Epoch: 0010 cost= 2.590357881\n",
      "Epoch: 0011 cost= 1.857197643\n",
      "Epoch: 0012 cost= 1.439858164\n",
      "Epoch: 0013 cost= 1.070681986\n",
      "Epoch: 0014 cost= 0.843941552\n",
      "Epoch: 0015 cost= 0.641899749\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9451\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+KWiDL9UlOGXijL8UlH/D4z2wAWXN+9dAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121315cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Exporting trained model to /tmp/tf_model...\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'/tmp/tf_model/saved_model.pb'\n",
      "Export finished\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "A Multilayer Perceptron implementation example using TensorFlow library.\n",
    "This example is using the MNIST database of handwritten digits\n",
    "(http://yann.lecun.com/exdb/mnist/)\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input], name=\"x\")\n",
    "y = tf.placeholder(\"float\", [None, n_classes], name=\"y\")\n",
    "\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.add(tf.matmul(layer_2, weights['out']), biases['out'], name = \"out_classes\")\n",
    "    return out_layer\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "norm = tf.random_normal([2, 3], mean=-1, stddev=4)\n",
    "output = tf.argmax(pred,1)\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            feed = {x: batch_x, y: batch_y}\n",
    "            _, c = sess.run([optimizer, cost], feed_dict=feed)\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                \"{:.9f}\".format(avg_cost))\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n",
    "    batch_x = mnist.train.next_batch(1)[0][0].reshape(1, 784)\n",
    "    \n",
    "    plt.imshow(batch_x.reshape(28, 28))\n",
    "    plt.show()\n",
    "    \n",
    "    bla = {\n",
    "         'x:0': batch_x\n",
    "    }\n",
    "    print(sess.run(output, feed_dict=bla))\n",
    "    \n",
    "    export_path = \"/tmp/tf_model\"  \n",
    "    print('Exporting trained model to {0}...'.format(export_path))\n",
    "\n",
    "    shutil.rmtree(export_path)\n",
    "\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "\n",
    "    tensor_info_x = tf.saved_model.utils.build_tensor_info(x)\n",
    "    tensor_info_output = tf.saved_model.utils.build_tensor_info(output)\n",
    "    tensor_info_test = tf.saved_model.utils.build_tensor_info(output)\n",
    "\n",
    "\n",
    "    \n",
    "    classification_signature = (\n",
    "      tf.saved_model.signature_def_utils.build_signature_def(\n",
    "          inputs={\n",
    "              'images': tensor_info_x\n",
    "          },\n",
    "          outputs={\n",
    "              'labels': tensor_info_output,\n",
    "              'labels2': tensor_info_output,\n",
    "          },\n",
    "          method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME)\n",
    "    )\n",
    "    \n",
    "    legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n",
    "    builder.add_meta_graph_and_variables(\n",
    "      sess, [tf.saved_model.tag_constants.SERVING],\n",
    "      signature_def_map={\n",
    "          tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: classification_signature\n",
    "      },\n",
    "      legacy_init_op=legacy_init_op)\n",
    "    builder.save()\n",
    "    print('Export finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from b'/tmp/tf_model/variables/variables'\n",
      "['images']\n",
      "['labels']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12a270898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([9])]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "batch_x, batch_y = mnist.train.next_batch(1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    meta_graph = tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], export_path)\n",
    "    signature = meta_graph.signature_def['serving_default']\n",
    "    inputs = list(signature.inputs._values.keys())\n",
    "    outputs = list(signature.outputs._values.keys())\n",
    "    print(inputs)\n",
    "    print(outputs)\n",
    "    \n",
    "    input_tensors = list(map(lambda n: sess.graph.get_tensor_by_name(signature.inputs[n].name), inputs))\n",
    "    output_tensors = list(map(lambda n: sess.graph.get_tensor_by_name(signature.outputs[n].name), outputs))\n",
    "\n",
    "    bla = {\n",
    "         'x:0': mnist.train.next_batch(1)[0][0].reshape(1, 784)\n",
    "    }\n",
    "    \n",
    "    plt.imshow(bla['x:0'].reshape(28, 28))\n",
    "    plt.show()\n",
    "    \n",
    "    result = sess.run(output_tensors, bla)\n",
    "    \n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
